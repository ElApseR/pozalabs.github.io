---
title: "BLSTM Tutorial"
layout: post
date: 2017-07-12 17:44
image: /assets/images/markdown.jpg
headerImage: False
tag:
- blstm
- lstm
- tensorflow
star: true
category: blog
author: hyerim
description: BLSTM summary with tensorflow
---

## Summary:

Bidrectional LSTM   설명이다.


## Basic formatting

This note **demonstrates** some of what [Markdown][1] is *capable of doing*.

And that's how to do it.

{% highlight html %}
This note **demonstrates** some of what [Markdown][some/link] is *capable of doing*.
{% endhighlight %}

---

## Headings

There are six levels of headings. They correspond with the six levels of HTML headings. You've probably noticed them already in the page. Each level down uses one more hash character. But we are using just 4 of them.

# Headings can be small

## Headings can be small

### Headings can be small

#### Headings can be small

{% highlight raw %}
# Heading
## Heading
### Heading
#### Heading
{% endhighlight %}

---

## Lists

### Ordered list

1. Item 1
2. A second item
3. Number 3

{% highlight raw %}
1. Item 1
2. A second item
3. Number 3
{% endhighlight %}

### Unordered list

* An item
* Another item
* Yet another item
* And there's more...

{% highlight raw %}
* An item
* Another item
* Yet another item
* And there's more...
{% endhighlight %}

---

## Paragraph modifiers

### Quote

> Here is a quote. What this is should be self explanatory. Quotes are automatically indented when they are used.

{% highlight raw %}
> Here is a quote. What this is should be self explanatory.
{% endhighlight raw %}

---

## URLs

URLs can be made in a handful of ways:

* A named link to [Mark It Down][3].
* Another named link to [Mark It Down](http://markitdown.net/)
* Sometimes you just want a URL like <http://markitdown.net/>.

{% highlight raw %}
* A named link to [MarkItDown][3].
* Another named link to [MarkItDown](http://markitdown.net/)
* Sometimes you just want a URL like <http://markitdown.net/>.
{% endhighlight %}

---

## Horizontal rule

A horizontal rule is a line that goes across the middle of the page.
It's sometimes handy for breaking things up.

{% highlight raw %}
---
{% endhighlight %}

---

## Images

Markdown can also contain images. I'll need to add something here sometime.

{% highlight raw %}
![Markdowm Image][/image/url]
{% endhighlight %}

![Markdowm Image][6]

*Figure Caption*?

{% highlight raw %}
![Markdowm Image][/image/url]
<figcaption class="caption">Photo by John Doe</figcaption>
{% endhighlight %}

![Markdowm Image][6]
<figcaption class="caption">Photo by John Doe</figcaption>

*Bigger Images*?

{% highlight raw %}
![Markdowm Image][/image/url]{: class="bigger-image" }
{% endhighlight %}

![Markdowm Image][6]{: class="bigger-image" }

---

## Code

A HTML Example:


## Bidirectional LSTM 

Bidirectional LSTM 에 대한 설명입니다.

앞에서 RNN 과 LSTM 모델에 대해 알려드렸습니다. Basic LSTM 모델은 이전 시간의 사건들이 다음 사건에 영향을 줄 것이라는 가정을 통해 만들어졌습니다. 하지만 이후의 step 또한 앞의 step 에 영향을 줄 수 있다면 이 모델을 어떻게 적용시킬 수 있을까요? 

이후의 step 의 영향도 반영한 모델이 BLSTM 모델입니다.

BLSTM 은 두 개의 LSTM 모델을 Concatenate 하여 사용합니다. Time step 이 1부터 t 까지 있다고 가정할 때 
forward lstm model 에서는 input 을 T = 1 일때부터 t 까지 순차적으로 적용시킵니다. 반대로 backward lstm model 에서 input 을 T = t 일때부터 1까지 거꾸로 input 을 주게 됩니다. 

자세한 내용은 Tensorflow 코드를 보면서 이해해보도록 하죠. 먼저 관련 라이브러리를 import 합니다.


```python
import tensorflow as tf
import numpy as np
from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("./mnist/data/", one_hot=True)
np.random.seed(144) # random seed 생성
```


```python
mnist.train.images[0]
```

<p>데이터는 이미지 데이터인 MNIST를 사용하도록 하겠습니다. MNIST 는 0 - 9 의 숫자 image data 이며 각 데이터는 28 x 28 의 matrix (data 는 28 x 28 길이의 array) 로 이루어져 있습니다. 각 matrix 의 element 는 0 에서 1사이의 값으로 값이 높을수록 어둡다는 것을 의미합니다.

앞에서 봤듯이 LSTM 은 sequence 형태를 요구합니다. 여기서 각 matrix 내의 row 28번의 time step 으로 나누어 넣어주게 됩니다. LSTM 에서는 이전의 값이 이후의 값에 영향을 준다고 가정하지만 이미지 데이터에서는 이 가정보다는 전후의 값들이 현재의 sequence 영향을 준다고 가정하는 것이 더 적합할 것입니다. <p>


```python
learning_rate = 0.001
total_steps = 5000000
batch_size = 256 # 한 번에 받을 데이터 개수 # mini batch 크기 설정

# mnist 데이터는 28*28 
# 1b개의 28 vector 을 input length 로 설정하고 
# sequence 의 개수를 28개로 설정함
input_length = 28 
input_sequence = 28
n_hidden = 64
input_classes = 10 # 0 - 9 클래스
```

관련 변수를 설정해 주었으니 image 를 input 으로 넣었을 때 이 image 가 0 에서 9 중에 어떤 숫자인지 맞추는 BLSTM 모델을 만들어 보고자 합니다.


```python
X = tf.placeholder(tf.float32,[None, input_sequence, input_length])
Y = tf.placeholder(tf.float32,[None, input_classes])

# 각 hidden state 에서 input_class 길이의 output 을 출력해야함
w_fw = tf.Variable(tf.random_normal([n_hidden, input_classes]))
w_bw = tf.Variable(tf.random_normal([n_hidden, input_classes]))
biases = tf.Variable(tf.random_normal([input_classes]))
```

X 는 28 x 28 의 matrix 로 이루어진 데이터를 받고 Y 는 실제 class (0 - 9) 를 의미하는 length 10 의 vector 를 받습니다. 그리고 각 forward lstm 모델과 backward lstm 모델에서 들어오는 weight 값을 받을 변수를 설정합니다. 

DropoutWrapper 는 모델에서 input 으로 주어진 data 에 대한 Overfitting 이 발생하지 않도록 만들어주는 모델입니다. 각 state 를 랜덤하게 비활성화시켜서 데이터를 더 random 하게 만들어줍니다. keep_prob 변수를 통해서 dropoutWrapper 의 확률값을 조정합니다. 


```python
keep_prob = tf.placeholder(tf.float32)
```

forward lstm 과 backward lstm 에서 사용할 cell을 생성합니다


```python
# lstm cell 생성
lstm_fw_cell = tf.nn.rnn_cell.LSTMCell(num_units = n_hidden, state_is_tuple = True)
lstm_fw_cell = tf.nn.rnn_cell.DropoutWrapper(lstm_fw_cell, output_keep_prob=keep_prob)

lstm_bw_cell = tf.nn.rnn_cell.LSTMCell(num_units = n_hidden, state_is_tuple = True)
lstm_bw_cell = tf.nn.rnn_cell.DropoutWrapper(lstm_bw_cell, output_keep_prob=keep_prob)
```

학습할 모델을 생성합니다


```python
outputs,_ = tf.nn.bidirectional_dynamic_rnn(lstm_fw_cell,lstm_bw_cell, X, dtype = tf.float32)
```


```python
outputs
```

기존의 lstm 과 달리 output 이 2개의 LSTMStateTuple 로 이루어져 있습니다. 각 output 에 가중치를 더해서 하나의 output 으로 만들어주는 과정이 필요합니다.

여기서 가장 헷갈리는 부분이 transpose 입니다. 왜 output 에 대해서 transpose를 하는 것인지 의문이 들 수 있습니다. tf.nn.bidirectional_dynamic_rnn 문서를 보시면 output 의 default 는 [batch_size,max_time,depth] 라고 나와있습니다. 각각 mini batch 의 크기 그리고 time step, hidden state 의 depth 를 의미합니다. 

 우리는 각 데이터마다 마지막 time step 의 결과값을 output 으로 선택해야 합니다. 그래야지 전체 step 이 반영된 output 을 얻을 수 있습니다.


```python
outputs_fw = tf.transpose(outputs[0], [1,0,2])
outputs_bw = tf.transpose(outputs[1], [1,0,2])
```


```python
outputs_fw[-1]
```


```python
#output = tf.concat(outputs_fw[-1],outputs_bw[-1],2)

#pred = tf.matmul(output,w_fw) + biases
```

matmul operation 연산 속도를 위해서 하나의 output 으로 먼저 합치고 전체에 대한 가중치를 주는 것도 좋은 방법입니다.


```python
pred = tf.matmul(outputs_fw[-1],w_fw) +tf.matmul(outputs_bw[-1],w_bw) + biases
```


```python
# 아래 코드는 이전과 동일합니다
cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = Y))
optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)
correct_prediction = tf.equal(tf.argmax(pred,1),tf.argmax(Y,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

#sess = tf.Session()
#sess.run(tf.global_variables_initializer())
```


```python
with tf.Session() as sess:
    sess.run(tf.global_variables_initializer())
    step = 1
    
    # training starts here!
    while step * batch_size < total_steps:
        batch_x, batch_y = mnist.train.next_batch(batch_size)
        
        # transform data to get 28 seq of 28 elements
        batch_x = batch_x.reshape((batch_size, input_length, input_sequence))
        
        # execute optimization (backprop)
        sess.run(optimizer, feed_dict={X: batch_x, Y: batch_y, keep_prob:0.9})
        
        if step % 10 == 0:
            # calculate batch accuracy
            acc = sess.run(accuracy, feed_dict={X: batch_x, Y: batch_y, keep_prob:1.0})
            
            # calculate batch loss
            loss = sess.run(cost, feed_dict={X: batch_x, Y: batch_y, keep_prob:1.0})
            print ('Iterations: ' + str(step*batch_size) + ', Minibatch Loss= ' + \
                  '{:.6f}'.format(loss) + ', Training Accuracy= ' + \
                  '{:.5f}'.format(acc))
        if step % 50 == 0:
            rand_train_index = np.random.randint(0, len(mnist.test.images), size=batch_size)
            test_data = mnist.test.images[rand_train_index,:].reshape((-1, input_length, input_sequence))
            test_label = mnist.test.labels[rand_train_index,:]

            print ('Test Accuracy:', sess.run(accuracy, feed_dict={X: test_data, Y: test_label, keep_prob:1.0}))
        step+=1
```
